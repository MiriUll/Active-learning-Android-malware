from utils.data_organisation import load_datasets_engineered_features
from utils.utils import *
from utils.config import *
import re
from shutil import copyfile
import os
from gensim.corpora import dictionary
import json
import glob


def gen_package_to_family_mapping():
    path = '/home/aesalem/Research/Android/Datasets/Malware/AMD/amd_data/'
    hash_to_family_mapping = {}
    for fam in os.listdir(path):
        if os.path.isdir(path + fam):
            print(path + fam)
            for app in glob.glob(path + fam + '/**/*.apk'):
                hash_to_family_mapping[(app.rsplit('/', 1)[1]).rsplit('.', 1)[0]] = fam
    with open('hash_to_family_mapping.txt', 'w+') as fh:
        fh.write(json.dumps(hash_to_family_mapping))


def copy_subset_to_new_path():
    with open('/home/miriam/malwaredetection/utils/source_codes/training_amd/fixed_amd_subset.txt', 'r') as f:
        for line in f:
            copyfile('/home/miriam/malwaredetection/utils/source_codes/training_amd/s.home.aesalem.Research.Android.Datasets.Malware.AMD.amd_data./' + line.strip('\n') + '.txt', '/home/miriam/malwaredetection/utils/source_codes/training_amd/amd_subset/' + line.strip('\n') + '.txt')
            copyfile('/home/miriam/malwaredetection/utils/source_codes/training_amd/s.home.aesalem.Research.Android.Datasets.Malware.AMD.amd_data./' + line.strip('\n') + '.tfidf', '/home/miriam/malwaredetection/utils/source_codes/training_amd/amd_subset/' + line.strip('\n') + '.tfidf')


def select_subset_and_save():
    with open('/home/miriam/malwaredetection/package_to_family.txt', 'r') as inf:
        package_to_family = eval(inf.read())
    source_code_dir = '/home/miriam/malwaredetection/utils/source_codes/training_amd/s.home.aesalem.Research.Android.Datasets.Malware.AMD.amd_data./'
    amd_data = {}
    for f in list(glob.glob(source_code_dir + '*.tfidf')):
        package = f.rsplit('/', 1)[1].split('.tfidf')[0]

        try:
            fam = package_to_family[package]
            if fam in amd_data:
                amd_data[fam].append(package)
            else:
                amd_data[fam] = [package]
        except KeyError:
            print('hash not in mapping')

    amd_subset = []
    '''while len(amd_subset) < 3000:
        for f in amd_data.keys():
            print(f, len(amd_data[f]))
            if len(amd_data) > 0:
                amd_subset += amd_data[f].pop(random.randint(0, len(amd_data[f])))'''
    for f in amd_data.keys():
        num_elements = int(0.2 * len(amd_data[f]))
        random.shuffle(amd_data[f])
        amd_subset += amd_data[f][:num_elements]
    print(len(amd_subset))
    with open('/home/miriam/malwaredetection/utils/source_codes/training_amd/fixed_subset.txt', 'w+') as f:
        for d in amd_subset:
            f.write(d + '\n')


def find_correlations_feature_vectors():
    #training_data, test_data, y_train, y_test, dataset_training, dataset_test = load_datasets_ordered(
    #    labeling_schema='original', compare_vt=False, ignore_ambiguous=False)
    #training_data, test_data, y_train, y_test, dataset_training, dataset_test = load_datasets(malware_features, goodware_features, 0,'original', compare_vt=False, ignore_ambiguous=False)
    training_data, test_data, y_train, y_test, dataset_training, dataset_test = load_datasets_engineered_features('original', False, False)
    training_data += test_data
    import numpy as np
    corr = np.corrcoef(np.array(training_data), rowvar=False)
    print(corr)
    for i, row in enumerate(corr):
        corrs = str(i) + ': '
        for j, column in enumerate(row):
            if i == j:
                break
            if abs(column) >= 0.7:
                #print(i, j, column)
                corrs += '(' + str(j) + ', ' + str(column) + '), '
        if not corrs.endswith(': '):
            print(corrs)


def find_correlations_result_metrics():
    from visualisation.plot_results import arguments, metrics_to_list
    result = json.load(open(arguments.result))
    arguments.training = 'training'
    arguments.metric = 'f1score'
    f1 = metrics_to_list(result)
    arguments.training = 'test'
    arguments.metric = 'mcc'
    mcc = metrics_to_list(result)
    print(np.corrcoef(f1, mcc))


def filter_tokenlist():
    id2token_dictionary = dictionary.Dictionary.load_from_text(corpus_path)
    token2id = []
    print(len(id2token_dictionary))
    tokenTuples = [tuple(map(int, i.split(' '))) for i in open(feature_mapping_path)]
    # with open('/home/miriam/malwaredetection/utils/source_codes/token_filtered_new.txt', 'w+') as fh:
    for i, token in id2token_dictionary.items():
        if re.match('^[A-Za-z0-9();-<>:./]+$', token):
            # fh.write(token.encode('utf-8') + '\n')
            token2id.append((i, token))
    tokens_filtered = dictionary.Dictionary()
    tokens_filtered.token2id = token2id
    print(dictionary.Dictionary.from_corpus(token2id))
    print()

if __name__ == '__main__':
    #find_correlations_result_metrics()
    '''id2token_dictionary = dictionary.Dictionary.load_from_text(corpus_path)
    tokenTuples = [tuple(map(int, i.split(' '))) for i in open(feature_mapping_path)]
    # with open('/home/miriam/malwaredetection/utils/source_codes/token_filtered_new.txt', 'w+') as fh:
    for i, token in id2token_dictionary.items():
        if not re.match('^[A-Za-z0-9();\-<>:./]+$', token):
            # fh.write(token.encode('utf-8') + '\n')
            print(token)'''
    training_data, test_data, y_train, y_test, dataset_training, dataset_test = load_datasets_engineered_features(
        'zero', True, True)
    good, mal = [], []
    for i, t in enumerate(training_data):
        if y_train[i] == 0:
            good.append(t[6])
        else:
            mal.append(t[6])

    print('malware: ', str(sum(mal) / len(mal)))
    print('goodware: ', str(sum(mal) / len(good)))
    #from utils. generate_feature_mapping import generate_feature_mapping
    #generate_feature_mapping()
    #with open('/home/anschutzm/PycharmProjects/malewaredetection/utils/fixed_amd_subset.txt', 'r') as f:
     #   print(len(f.read().splitlines()))
    #wih open('/home/anschutzm/PycharmProjects/malewaredetection/utils/fixed_amd_subset_hashes.txt', 'r') as out:
       # print(len(out.read().splitlines()))
    """fg = Feature_Mapping_Generator()
    fg.retrieve_source_codes(maleware_path)
    fg.retrieve_source_codes(goodware_path)
    print(len(fg.source_code))
    fg.build_feature_mapping()
    fg.export_mapping()
    wg = Window_Generator()
    for i in range(0, 50):
        res = wg.next_training_data(True)
        while res is not None:
            res = wg.next_training_data(False)"""
    #training_data, test_data = preprocess.preprocess(True)
    #a = AnalysedAPK(goodware_path + '00a7478f356bfe2d1ed19785f002c1b15f2a3827404e3009c320fdfbf505be2a.apk', 0)
    #a.export_graph(goodware_path + 'export')
    #from networkx import read_edgelist
    #g = read_edgelist(goodware_path + 'export')
    #print g
    #source_code_dir = '/home/miriam/malewaredetection/utils/source_codes/'
    #training_data, y_train = load_features_from_path([source_code_dir + 's.home.aesalem.Research.Android.Datasets.Goodware.google_play./'], 0)
    '''_, _, y_train_orig, y_test_orig, _, _ = load_datasets_ordered(balance_factor=1.0, labeling_schema='original', compare_vt=False, ignore_ambiguous=False)
    _, _, y_train_zero, y_test_zero, _, _ = load_datasets_ordered(balance_factor=1.0, labeling_schema='zero', compare_vt=True, ignore_ambiguous=False)
    _, _, y_train_fifty, y_test_fifty, _, _ = load_datasets_ordered(balance_factor=1.0, labeling_schema='fifty_percent', compare_vt=True, ignore_ambiguous=False)


    for i, l in enumerate(y_test_orig):
        if l == y_test_fifty[i] and l == y_test_zero[i]:
            print(i)'''
