import glob
import random
import numpy as np
import json
import re

vt_reports_path = '/home/aesalem/Research/dejavu/data/vt_reports/'
package_hash_mapping = '/home/aesalem/Research/dejavu/data/lookup_structs/package_to_hash.txt'


# package_hash_mapping = '/home/anschutzm/PycharmProjects/malewaredetection/utils/package_to_hash.txt'


def load_datasets_for_validation(labeling_schema, compare_vt, ignore_ambiguous, balance_factor):
    datasets_training = ['validation: google_play', 'validation: amd']
    source_code_dir = '/home/miriam/malwaredetection/utils/source_codes/training_amd/'
    training_data, y_train = load_features_from_path(
        [source_code_dir + 's.home.aesalem.Research.Android.Datasets.Goodware.google_play./'],
        0, labeling_schema, compare_vt=compare_vt, ignore_ambiguous=ignore_ambiguous)
    t, y = load_features_from_path([source_code_dir + 's.home.aesalem.Research.Android.Datasets.Malware.AMD.amd_data./']
                                   , 1, labeling_schema, compare_vt=compare_vt, ignore_ambiguous=ignore_ambiguous)
    t = t[:int(balance_factor * len(training_data))]
    y = y[:int(balance_factor * len(training_data))]
    training_data += t
    y_train += y
    training_data, y_train = randomize_dataset(training_data, y_train)

    test_data = training_data
    y_test = y_train
    datasets_test = datasets_training

    return training_data, test_data, y_train, y_test, datasets_training, datasets_test


def load_datasets_ordered(labeling_schema, compare_vt, ignore_ambiguous):
    """
    generate labeled training and test data sets based on existing datasets
    :return: training, test data set and corresponding labels
    """
    datasets_training = ['google_play', 'amd_all']
    source_code_dir = '/home/miriam/malwaredetection/utils/source_codes/training_subset/'
    training_data, y_train = load_features_from_path(
        [source_code_dir + 's.home.aesalem.Research.Android.Datasets.Goodware.google_play./'],
        0, labeling_schema, compare_vt=compare_vt, ignore_ambiguous=ignore_ambiguous)
    # t, y = load_features_from_path([source_code_dir + 's.home.aesalem.Research.Android.Datasets.Malware.AMD.amd_data./'], 1, labeling_schema, compare_vt=compare_vt, ignore_ambiguous=ignore_ambiguous)
    t, y = load_features_from_path([source_code_dir + 'amd/'], 1, labeling_schema, compare_vt=compare_vt,
                                   ignore_ambiguous=ignore_ambiguous)
    # t = t[:int(len(training_data))]
    # y = y[:int(len(training_data))]
    training_data += t
    y_train += y

    # datasets_test = ['malgenome']
    datasets_test = ['piggybacking_orig', 'piggybacking_backed']
    # test_data, y_test = load_features_from_path([source_code_dir + 's.home.aesalem.Research.Android.Datasets.Malware.MalGenome.genome./'],
    #                                            1, labeling_schema, compare_vt=compare_vt, ignore_ambiguous=ignore_ambiguous)
    test_data, y_test = load_features_from_path(
        [source_code_dir + 's.home.aesalem.Research.Android.Datasets.Malware.AndroZoo_Piggybacking.piggybacked./'], 1,
        labeling_schema, compare_vt=compare_vt, ignore_ambiguous=False)
    # test_data += t
    # y_test += y
    t, y = load_features_from_path(
        [source_code_dir + 's.home.aesalem.Research.Android.Datasets.Malware.AndroZoo_Piggybacking.original./'], 0,
        labeling_schema, compare_vt, ignore_ambiguous=False)
    test_data += t
    y_test += y

    training_data, y_train = randomize_dataset(training_data, y_train)

    return training_data, test_data, y_train, y_test, datasets_training, datasets_test


def load_datasets_engineered_features(labeling_schema, compare_vt, ignore_ambiguous):
    datasets_training = ['google_play_static', 'amd_subset_static']
    source_code_dir = '/home/aesalem/Research/dejavu/data/feature_vectors/'
    training_data, y_train = load_features_from_path([source_code_dir + 'gplay/static/'], 0, labeling_schema,
                                                     compare_vt, ignore_ambiguous, criterion='*.static')
    t, y = load_fixed_subset(1, labeling_schema, compare_vt, ignore_ambiguous)
    training_data += t
    y_train += y

    training_data, y_train = randomize_dataset(training_data, y_train)

    datasets_test = ['piggybacking_orig_static', 'piggybacking_backed_static']
    test_data, y_test = load_features_from_path([source_code_dir + 'piggybacked_only/static/'], 1, labeling_schema,
                                                compare_vt, ignore_ambiguous, criterion='*.static')
    t, y = load_features_from_path([source_code_dir + 'original_only/static/'], 0, labeling_schema, compare_vt,
                                   ignore_ambiguous, criterion='*.static')
    test_data += t
    y_test += y

    return training_data, test_data, y_train, y_test, datasets_training, datasets_test


def load_datasets(maldirs, gooddirs, percent_test, labeling_schema, compare_vt, ignore_ambiguous,
                  feature_regex='*.tfidf'):
    """
    generate labeled training and test data sets with random training - test data
    :param compare_vt: boolean if original labels are overwritten by vt_reports
    :param ignore_ambiguous: boolean if ambiguous reports are ignored
    :param labeling_schema: schema to decide if vt reports malicious
    :param feature_regex: regex to filter feature types, default *.tfidf
    :param maldirs: list of malware paths
    :param gooddirs: list of goodware paths
    :param percent_test: percentage of test data
    :return: training, test data set and corresponding labels
    """
    # load good- and malware features from paths
    all_mal_features, y = load_features_from_path(maldirs, 1, labeling_schema, compare_vt=compare_vt,
                                                  ignore_ambiguous=ignore_ambiguous, criterion=feature_regex)
    all_good_features, y2 = load_features_from_path(gooddirs, 0, labeling_schema, criterion=feature_regex,
                                                    compare_vt=compare_vt, ignore_ambiguous=ignore_ambiguous)
    y += y2
    all_features = all_mal_features + all_good_features

    # randomize order (use zip to remember feature <-> label mapping)
    all_features, y = randomize_dataset(all_features, y)

    # divide data into train and test set
    training_data, test_data, y_train, y_test = split_dataset(list(all_features), list(y), percent_test)

    return training_data, test_data, y_train, y_test, 'random', 'random'


def load_features_from_path(paths, label, labeling_schema, compare_vt, ignore_ambiguous, criterion='.tfidf'):
    """
    load tfidf features from path system
    :param ignore_ambiguous: true if ambiguous vt reports are ignored for training
    :param compare_vt: False if labels arent compared to vt reports
    :param criterion: feature data type
    :param paths: list of paths to load data from, important: path must end with /
    :param label: label to label data with
    :return:
    """
    if compare_vt:
        package_to_hash = load_hash_package_mapping()
    if isinstance(paths, str):
        paths = [paths]
    feature_list, labels = [], []
    for path in paths:
        print('loading features in path ' + path)
        for f in list(glob.glob(path + '*' + criterion)):
            if compare_vt:
                package = f.rsplit('/', 1)[1].split(criterion)[0]
                label = label_from_vt_report(package_to_hash, package, label, labeling_schema)
                if ignore_ambiguous and label < 0:
                    continue
            feature_list += [np.asarray(eval(open(f).read()))]
            labels.append(label)
    return feature_list, labels


def load_fixed_subset(label, labeling_schema, compare_vt, ignore_ambiguous, fileextension='.static'):
    if compare_vt:
        package_to_hash = load_hash_package_mapping()
    print('Load amd subset features')
    path = '/home/aesalem/Research/dejavu/data/feature_vectors/amd/static/'
    feature_list, labels = [], []
    ignored = 0
    with open('/home/miriam/malwaredetection/utils/source_codes/training_amd/fixed_amd_subset_hashes.txt', 'r') as f:
        for line in f:
            line = line.strip('\n')
            if compare_vt:
                label = label_from_vt_report(package_to_hash, line, label, labeling_schema, True)
                if ignore_ambiguous and label < 0:
                    continue
            try:
                feature_list += [np.asarray(eval(open(path + line + fileextension).read()))]
                labels.append(label)
            except IOError:
                ignored += 1
    print('Ignored %s files' % ignored)
    return feature_list, labels


def randomize_dataset(all_features, y):
    """
    shuffle dataset and keep feature -> label mapping
    :param all_features:
    :param y:
    :return:
    """
    z = zip(all_features, y)
    random.shuffle(z)
    all_features, y = list(zip(*z))
    return list(all_features), list(y)


def load_hash_package_mapping():
    with open(package_hash_mapping, 'r') as inf:
        dict_from_file = eval(inf.read())
    return dict_from_file


def label_from_vt_report(package_to_hash, package, backup_label, schema, hash=False):
    """
    try to load label from vt, else use backup label
    :param package_to_hash: mapping package -> hash
    :param package: package of app
    :param backup_label: backup label if there is no vt_report
    :return: label to classify app
    """
    try:
        if re.match('^[A-Fa-f0-9]{64}$', package):
            app_report = package + '.report'
        else:
            app_report = package_to_hash[package] + '.report'
        vt_report = eval(open(vt_reports_path + app_report).read())
        pos = vt_report['positives']
        # print(backup_label, pos, vt_report["total"])
        if schema == 'ambiguous':
            if pos == 0:
                label = 0
            else:
                label = 1 if pos / float(vt_report["total"]) >= 0.50 else -1
        elif schema == 'fifty_percent':
            label = 1 if pos / float(vt_report["total"]) >= 0.50 else 0
        elif schema == 'zero':
            label = 0 if pos / float(vt_report["total"]) <= 0.05 else 1
        # print(schema, label)
        return label
    except KeyError as e:
        return backup_label


def split_dataset(data, labels, percentage):
    """
    split dataset into subsets
    :param data: dataset as list to split
    :param labels: labels of dataset as list
    :param percentage: percentage of split data
    :return: two datasets and corresponding labels
    """
    num_split = int(round(percentage * len(data)))
    data_split, y_split = data[:num_split], labels[:num_split]
    data_rest, y_rest = data[num_split:], labels[num_split:]
    return data_rest, data_split, y_rest, y_split


def save_metrics_to_file(path, metricsDict):
    with open(path, 'w+') as f:
        json.dump(metricsDict, f, sort_keys=True, indent=4)


def save_decision_tree(estimator, Xte):
    with open(results_folder + 'tree' + non_default_arguments() + '.txt', 'w+') as fh:
        n_nodes = estimator.tree_.node_count
        children_left = estimator.tree_.children_left
        children_right = estimator.tree_.children_right
        feature = estimator.tree_.feature
        threshold = estimator.tree_.threshold
        value = estimator.tree_.value

        # The tree structure can be traversed to compute various properties such
        # as the depth of each node and whether or not it is a leaf.
        node_depth = np.zeros(shape=n_nodes, dtype=np.int64)
        is_leaves = np.zeros(shape=n_nodes, dtype=bool)
        stack = [(0, -1)]  # seed is the root node id and its parent depth
        while len(stack) > 0:
            node_id, parent_depth = stack.pop()
            node_depth[node_id] = parent_depth + 1

            # If we have a test node
            if children_left[node_id] != children_right[node_id]:
                stack.append((children_left[node_id], parent_depth + 1))
                stack.append((children_right[node_id], parent_depth + 1))
            else:
                is_leaves[node_id] = True

        fh.write("The binary tree structure has %s nodes and has "
                 "the following tree structure:"
                 % n_nodes)
        for i in range(n_nodes):
            if is_leaves[i]:
                fh.write("%snode=%s leaf node -> %s." % (node_depth[i] * "\t", i, np.argmax(value[i][0])))
            else:
                fh.write("%snode=%s test node: go to node %s if X[:, %s] <= %s else to "
                         "node %s."
                         % (node_depth[i] * "\t",
                            i,
                            children_left[i],
                            feature[i],
                            threshold[i],
                            children_right[i],
                            ))
        fh.write()

        # First let's retrieve the decision path of each sample. The decision_path
        # method allows to retrieve the node indicator functions. A non zero element of
        # indicator matrix at the position (i, j) indicates that the sample i goes
        # through the node j.

        node_indicator = estimator.decision_path(Xte)

        # Similarly, we can also have the leaves ids reached by each sample.

        leave_id = estimator.apply(Xte)

        # Now, it's possible to get the tests that were used to predict a sample or
        # a group of samples. First, let's make it for the sample.

        sample_id = 0
        node_index = node_indicator.indices[node_indicator.indptr[sample_id]:
                                            node_indicator.indptr[sample_id + 1]]

        fh.write('Rules used to predict sample %s: ' % sample_id)
        for node_id in node_index:
            if leave_id[sample_id] == node_id:
                continue
            if (Xte[sample_id][feature[node_id]] <= threshold[node_id]):
                threshold_sign = "<="
            else:
                threshold_sign = ">"

            fh.write("decision id node %s : (Xte[%s, %s] (= %s) %s %s)"
                     % (node_id,
                        sample_id,
                        feature[node_id],
                        Xte[sample_id][feature[node_id]],
                        threshold_sign,
                        threshold[node_id]))

        # For a group of samples, we have the following common node.
        sample_ids = [0, 1]
        common_nodes = (node_indicator.toarray()[sample_ids].sum(axis=0) ==
                        len(sample_ids))

        common_node_id = np.arange(n_nodes)[common_nodes]

        fh.write("\nThe following samples %s share the node %s in the tree"
                 % (sample_ids, common_node_id))
        fh.write("It is %s %% of all nodes." % (100 * len(common_node_id) / n_nodes,))
