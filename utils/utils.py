import numpy as np
import json


def save_metrics_to_file(path, metricsDict):
    with open(path, 'w+') as f:
        json.dump(metricsDict, f, sort_keys=True, indent=4)


def save_decision_tree(estimator, Xte, filename):
    with open(filename, 'w+') as fh:
        n_nodes = estimator.tree_.node_count
        children_left = estimator.tree_.children_left
        children_right = estimator.tree_.children_right
        feature = estimator.tree_.feature
        threshold = estimator.tree_.threshold
        value = estimator.tree_.value

        # The tree structure can be traversed to compute various properties such
        # as the depth of each node and whether or not it is a leaf.
        node_depth = np.zeros(shape=n_nodes, dtype=np.int64)
        is_leaves = np.zeros(shape=n_nodes, dtype=bool)
        stack = [(0, -1)]  # seed is the root node id and its parent depth
        while len(stack) > 0:
            node_id, parent_depth = stack.pop()
            node_depth[node_id] = parent_depth + 1

            # If we have a test node
            if children_left[node_id] != children_right[node_id]:
                stack.append((children_left[node_id], parent_depth + 1))
                stack.append((children_right[node_id], parent_depth + 1))
            else:
                is_leaves[node_id] = True

        fh.writelines("The binary tree structure has %s nodes and has "
                      "the following tree structure:"
                      % n_nodes)
        for i in range(n_nodes):
            if is_leaves[i]:
                fh.writelines("\n%snode=%s leaf node -> %s." % (node_depth[i] * "\t", i, value[i][0]))
            else:
                fh.writelines("\n%snode=%s test node: go to node %s if X[:, %s] <= %s else to "
                              "node %s."
                              % (node_depth[i] * "\t",
                                 i,
                                 children_left[i],
                                 feature[i],
                                 threshold[i],
                                 children_right[i],
                                 ))
        fh.writelines('')

        # First let's retrieve the decision path of each sample. The decision_path
        # method allows to retrieve the node indicator functions. A non zero element of
        # indicator matrix at the position (i, j) indicates that the sample i goes
        # through the node j.

        node_indicator = estimator.decision_path(Xte)

        # Similarly, we can also have the leaves ids reached by each sample.

        leave_id = estimator.apply(Xte)

        # Now, it's possible to get the tests that were used to predict a sample or
        # a group of samples. First, let's make it for the sample.

        sample_id = 0
        node_index = node_indicator.indices[node_indicator.indptr[sample_id]:
                                            node_indicator.indptr[sample_id + 1]]

        fh.write('Rules used to predict sample %s: ' % sample_id)
        for node_id in node_index:
            if leave_id[sample_id] == node_id:
                continue
            if Xte[sample_id][feature[node_id]] <= threshold[node_id]:
                threshold_sign = "<="
            else:
                threshold_sign = ">"

            fh.writelines("\ndecision id node %s : (Xte[%s, %s] (= %s) %s %s)"
                          % (node_id,
                             sample_id,
                             feature[node_id],
                             Xte[sample_id][feature[node_id]],
                             threshold_sign,
                             threshold[node_id]))

        # For a group of samples, we have the following common node.
        sample_ids = [0, 1]
        common_nodes = (node_indicator.toarray()[sample_ids].sum(axis=0) ==
                        len(sample_ids))

        common_node_id = np.arange(n_nodes)[common_nodes]

        fh.writelines("\nThe following samples %s share the node %s in the tree"
                      % (sample_ids, common_node_id))
        fh.writelines("It is %s %% of all nodes." % (100 * len(common_node_id) / n_nodes,))


def non_default_arguments(arguments, argumentParser):
    argument_string = ''
    for arg in vars(arguments):
        if getattr(arguments, arg) != argumentParser.get_default(arg):
            argument_string += '-' + arg.capitalize() + str(getattr(arguments, arg)).capitalize()
    return argument_string
