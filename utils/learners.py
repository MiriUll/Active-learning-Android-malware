from sklearn.naive_bayes import MultinomialNB
import numpy, sys
from sklearn import tree
from sklearn.neighbors import KNeighborsClassifier

from config import aion_log_file, aion_path
from sklearn.model_selection import cross_val_score
sys.path.insert(0, aion_path)
import Aion
from Aion.conf.config import *

Aion.conf.config.LOG_FILE = aion_log_file
from Aion.utils.misc import specificity_score
from Aion.utils.graphics import *
from sklearn.metrics import *


def calculateMetrics_multiclass(truth, predicted):
    """
    Calculates and returns a set of metrics from ground truth and predicted vectors
    :param truth: A list of ground truth labels
    :type truth: list
    :param predicted: A list of predicted labels
    :type predicted: list
    :return: A dict of metrics including accuracy, recall, specificity, precision, and F1-score
    """
    try:
        # Sanity check
        if not len(truth) == len(predicted):
            prettyPrint("The two vectors have different dimensionality", "warning")
            return {}

        metrics = {}
        # Calculate different mterics
        metrics["accuracy"] = accuracy_score(truth, predicted)
        metrics["recall"] = recall_score(truth, predicted)
        metrics["specificity"] = specificity_score(truth, predicted) # From Aion.utils.misc
        metrics["precision"] = precision_score(truth, predicted)
        metrics["f1score"] = f1_score(truth, predicted)

    except Exception as e:
        prettyPrintError(e)
        return {}

    return metrics


def predictAndTestNB(X, y, Xtest=[], ytest=[], alpha=1.0):
    try:
        # Define classifier and cross validation iterator
        clf = MultinomialNB(alpha=alpha)
        #clf = KNeighborsClassifier(n_neighbors=5)
        # Start the cross validation learning
        X, y, Xtest, ytest = numpy.array(X), numpy.array(y), numpy.array(Xtest), numpy.array(ytest)
        # Fit model
        clf.fit(X, y)
        # Validate and test model
        predicted = clf.predict(X)
        if 1 < len(Xtest) == len(ytest) > 1:
            predicted_test = clf.predict(Xtest)
        else:
            predicted_test = []

    except Exception as e:
        print(e)
        return None, [], []

    return clf, predicted, predicted_test


def kFoldNB(kfold, X, y, Xtest=[], ytest=[], alpha=1.0):
    '''kf = KFold(n_splits=kfold)
    accuracies = []

    for train_index, test_index in kf.split(X):
        print("Train:", train_index, "Validation:", test_index)
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        clf = MultinomialNB(alpha=alpha)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)

        accuracies.append(accuracy_score(y_test, y_pred))'''

    clf, predicted, predicted_test = predictAndTestNB(X, y, Xtest, ytest, alpha)

    cv_scores = list(cross_val_score(clf, X, y, cv=kfold))

    return clf, predicted, predicted_test, cv_scores


def predictAndTestDT(X, y, Xtest=[], ytest=[]):
    try:
        # Define classifier and cross validation iterator
        clf = tree.DecisionTreeClassifier()
        #clf = KNeighborsClassifier(n_neighbors=5)
        # Start the cross validation learning
        X, y, Xtest, ytest = numpy.array(X), numpy.array(y), numpy.array(Xtest), numpy.array(ytest)
        # Fit model
        clf.fit(X, y)
        # Validate and test model
        predicted = clf.predict(X)
        if 1 < len(Xtest) == len(ytest) > 1:
            predicted_test = clf.predict(Xtest)
        else:
            predicted_test = []

    except Exception as e:
        print(e)
        return None, [], []

    return clf, predicted, predicted_test


def kFoldDT(kfold, X, y, Xtest=[], ytest=[]):
    '''kf = KFold(n_splits=kfold)
    accuracies = []

    for train_index, test_index in kf.split(X):
        print("Train:", train_index, "Validation:", test_index)
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        clf = MultinomialNB(alpha=alpha)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)

        accuracies.append(accuracy_score(y_test, y_pred))'''

    clf, predicted, predicted_test = predictAndTestDT(X, y, Xtest, ytest)

    cv_scores = list(cross_val_score(clf, X, y, cv=kfold))

    return clf, predicted, predicted_test, cv_scores
